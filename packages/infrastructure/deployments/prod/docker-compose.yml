version: '3.8'

services:
  nginx:
    build:
      context: .
      dockerfile: Dockerfile.nginx
    container_name: express_nginx
    ports:
      - "80:80"
    depends_on:
      - api
    networks:
      - common
    restart: unless-stopped
    command: sh -c "rm -f /etc/nginx/conf.d/default.conf && nginx -g 'daemon off;'"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M

  postgres:
    build:
      context: ../../../../
      dockerfile: packages/infrastructure/common/config/Dockerfile.postgres
    container_name: express_postgres
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: express_nest_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - common
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: express_redis
    restart: always
    networks:
      - common
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio:latest
    container_name: minio_container
    ports:
      - '9000:9000'
      - '9001:9001'
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    networks:
      - common
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper_container
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - common

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka_container
    restart: always
    depends_on:
      - zookeeper
    networks:
      - common
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_CLEANER_ENABLE: "false"
    healthcheck:
      test: ["CMD", "bash", "-c", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 15s

  api:
    build:
      context: ../../../../
      dockerfile: packages/infrastructure/Dockerfile
    restart: unless-stopped
    expose:
      - "3000"
    env_file:
      - ./.env
    environment:
      APP_ROLE: API
      NODE_ENV: production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - common
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
    healthcheck:
      test: ["CMD", "wget", "--header", "X-Health-Key: prod_health_secret_2024", "--spider", "-q", "http://127.0.0.1:3000/api/v1/health/live"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 60s

  worker:
    build:
      context: ../../../../
      dockerfile: packages/infrastructure/Dockerfile
    restart: unless-stopped
    env_file:
      - ./.env
    environment:
      APP_ROLE: WORKER
      NODE_ENV: production
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - common
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
    healthcheck:
      test: ["CMD", "node", "-e", "process.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3


  metrics-proxy-api:
    build:
      context: ../../common/config
      dockerfile: Dockerfile.metrics-proxy
    container_name: metrics_proxy_api_prod
    env_file:
      - ./.env
    environment:
      - HEALTH_CHECK_SECRET=${HEALTH_CHECK_SECRET}
      - TARGET_HOST=api
      - TARGET_PORT=3000
      - PROXY_PORT=9100
    depends_on:
      - api
    restart: unless-stopped
    networks:
      - common
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 64M

  metrics-proxy-worker:
    build:
      context: ../../common/config
      dockerfile: Dockerfile.metrics-proxy
    container_name: metrics_proxy_worker_prod
    env_file:
      - ./.env
    environment:
      - HEALTH_CHECK_SECRET=${HEALTH_CHECK_SECRET}
      - TARGET_HOST=worker
      - TARGET_PORT=3000
      - PROXY_PORT=9100
    depends_on:
      - worker
    restart: unless-stopped
    networks:
      - common
    deploy:
      resources:
        limits:
          cpus: '0.1'
          memory: 64M

  prometheus:
    build:
      context: ../../common/config
      dockerfile: Dockerfile.prometheus
    container_name: prometheus_prod
    ports:
      - "9090:9090"
    volumes:
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    depends_on:
      - metrics-proxy-api
      - metrics-proxy-worker
    restart: unless-stopped
    networks:
      - common
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  grafana:
    build:
      context: ../../common/config
      dockerfile: Dockerfile.grafana
    container_name: grafana_prod
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    restart: unless-stopped
    networks:
      - common
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

networks:
  common:
    driver: bridge

volumes:
  postgres_data:
  minio_data:
  prometheus_data:
  grafana_data:
